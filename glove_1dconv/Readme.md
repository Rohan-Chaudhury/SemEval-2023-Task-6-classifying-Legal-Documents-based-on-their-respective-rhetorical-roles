### This contains an ipynb file to test:
1. Glove Embedding + Fully Connected Layer
2. Glove Embedding + 1D Conv + softmax

### How to run: 
1. Spin up a jupyter notebook or google colab
2. Download dataset: https://github.com/Legal-NLP-EkStep/rhetorical-role-baseline
3. Provide paths to data in the variables
4. Run all cells

### Results:

1. Glove Embedding + Fully Connected Layer: macro F1: ~ 0.26
2. Glove Embedding + 1D Conv + softmax: macro F1: ~ 0.31