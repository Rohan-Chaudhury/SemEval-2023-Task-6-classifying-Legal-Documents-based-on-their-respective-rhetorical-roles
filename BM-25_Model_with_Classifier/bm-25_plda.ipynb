{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers \n",
    "%pip install https://github.com/sadrasabouri/plda/tarball/master\n",
    "!wget https://storage.googleapis.com/indianlegalbert/OPEN_SOURCED_FILES/Rhetorical_Role_Benchmark/Data/train.json\n",
    "!wget https://storage.googleapis.com/indianlegalbert/OPEN_SOURCED_FILES/Rhetorical_Role_Benchmark/Data/dev.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior installations and downloading of train and validation file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T19:30:58.323169Z",
     "iopub.status.busy": "2022-11-27T19:30:58.322759Z",
     "iopub.status.idle": "2022-11-27T19:31:03.306405Z",
     "shell.execute_reply": "2022-11-27T19:31:03.305446Z",
     "shell.execute_reply.started": "2022-11-27T19:30:58.323132Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Imports of necessary packages\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.functional import normalize\n",
    "import plda\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "PLDA_classifier = plda.Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Block of code imports necessary packages including transformers, and sklearn classifiers.\n",
    "It also initialize Decision Tree regressor with squared mean error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T19:31:08.244593Z",
     "iopub.status.busy": "2022-11-27T19:31:08.243987Z",
     "iopub.status.idle": "2022-11-27T19:31:31.353546Z",
     "shell.execute_reply": "2022-11-27T19:31:31.352431Z",
     "shell.execute_reply.started": "2022-11-27T19:31:08.244556Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import bm-25 tokenizer and model \n",
    "tokenizer = AutoTokenizer.from_pretrained('facebook/spar-wiki-bm25-lexmodel-query-encoder')\n",
    "query_encoder = AutoModel.from_pretrained('facebook/spar-wiki-bm25-lexmodel-query-encoder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bm-23 tokenizer and model is initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T19:31:44.596263Z",
     "iopub.status.busy": "2022-11-27T19:31:44.594932Z",
     "iopub.status.idle": "2022-11-27T19:31:44.612228Z",
     "shell.execute_reply": "2022-11-27T19:31:44.610426Z",
     "shell.execute_reply.started": "2022-11-27T19:31:44.596213Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    return text.strip()\n",
    "\n",
    "def generate_word_embedding(query):\n",
    "    input_ids = tokenizer(query, truncation=True, return_tensors='pt')\n",
    "\n",
    "    # Compute embeddings: take the last-layer hidden state of the [CLS] token\n",
    "    query_emb = query_encoder(**input_ids).last_hidden_state[:, 0, :]\n",
    "    return query_emb\n",
    "\n",
    "def predict(query, labels_dev):\n",
    "    tensor_value = generate_word_embedding(query)\n",
    "    numpy_value = tensor_value.detach().numpy()\n",
    "    numpy_value = np.squeeze(numpy_value)\n",
    "    predictions, log_p_predictions = PLDA_classifier.predict(numpy_value)\n",
    "    predictions = labels_dev[predictions]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **clean_text()** : Function to clean text.\n",
    "2. **generate_word_embedding()**: Function to generate text embedding using english text. \n",
    "3. **predict()** : Function to take input as dev data and generate embedding of it. This embedding is then used as input to trained classifier model and output is predicted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-11-27T19:31:52.610067Z",
     "iopub.status.busy": "2022-11-27T19:31:52.609703Z",
     "iopub.status.idle": "2022-11-27T19:31:52.948737Z",
     "shell.execute_reply": "2022-11-27T19:31:52.947760Z",
     "shell.execute_reply.started": "2022-11-27T19:31:52.610034Z"
    },
    "id": "GdsXvMfqsqBB",
    "outputId": "675ad746-ac27-4284-c639-63f1f18b9d5d",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train = json.load(open('train.json'))\n",
    "dev = json.load(open('dev.json'))\n",
    "labels_all=[]\n",
    "data=[]\n",
    "\n",
    "for i in train:\n",
    "  for annotations in i['annotations']:\n",
    "    for results in annotations['result']:\n",
    "      data.append(clean_text(results['value']['text']))\n",
    "      labels_all.append(results['value']['labels'][0])\n",
    "\n",
    "TRAIN_SIZE = len(labels_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and dev data is loaded. Englist text and its corresponding labels are stored in an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-11-27T19:32:00.199117Z",
     "iopub.status.busy": "2022-11-27T19:32:00.198185Z"
    },
    "id": "vtjfE6zVtiVn",
    "outputId": "b5408010-fefd-4550-cb07-facfe1aab4e7",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "labels = list(set(labels_all))\n",
    "y = []\n",
    "progress = 0\n",
    "for sentence, label in zip(data[:TRAIN_SIZE],\n",
    "                        labels_all[:TRAIN_SIZE]):\n",
    "    tensor_value = generate_word_embedding(sentence)   \n",
    "    numpy_value = tensor_value.detach().numpy()\n",
    "    numpy_value = np.squeeze(numpy_value)                 \n",
    "    X.append(numpy_value)\n",
    "    y.append(labels.index(label))\n",
    "    progress += 1\n",
    "    if progress % 500 == 0:\n",
    "        print('Progress Percent = {}%'.format(100 * progress / TRAIN_SIZE))\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This piece of code aims to use training data, create embeddings for query text and save it in npy file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Regression Tree classifier\n",
    "PLDA_classifier.fit_model(np.array(X), np.array(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier model which is initialized, is trained with training data and corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-15T08:52:24.140774Z",
     "iopub.status.busy": "2022-11-15T08:52:24.140384Z",
     "iopub.status.idle": "2022-11-15T09:01:44.921407Z",
     "shell.execute_reply": "2022-11-15T09:01:44.920040Z",
     "shell.execute_reply.started": "2022-11-15T08:52:24.140741Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "labels_all_dev=[]\n",
    "data_dev=[]\n",
    "\n",
    "for i in dev:\n",
    "  for annotations in i['annotations']:\n",
    "    for results in annotations['result']:\n",
    "      data_dev.append(clean_text(results['value']['text']))\n",
    "      labels_all_dev.append(results['value']['labels'][0])\n",
    "        \n",
    "preds_dev=[]\n",
    "labels_dev = list(set(labels_all))\n",
    "for query in data_dev:\n",
    "    preds = predict(query, labels_dev)\n",
    "    preds_dev.append(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training of model, validation or dev dataset is used and stored to array for prediction. Fitted model is used for getting output of prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-15T04:08:10.259941Z",
     "iopub.status.busy": "2022-11-15T04:08:10.259550Z",
     "iopub.status.idle": "2022-11-15T04:08:10.283320Z",
     "shell.execute_reply": "2022-11-15T04:08:10.282179Z",
     "shell.execute_reply.started": "2022-11-15T04:08:10.259903Z"
    }
   },
   "source": [
    "preds_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-15T09:01:44.924896Z",
     "iopub.status.busy": "2022-11-15T09:01:44.924205Z",
     "iopub.status.idle": "2022-11-15T09:01:44.962401Z",
     "shell.execute_reply": "2022-11-15T09:01:44.961362Z",
     "shell.execute_reply.started": "2022-11-15T09:01:44.924857Z"
    },
    "id": "nG5uo7qWt4gO",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Calculate score\n",
    "f1score=f1_score(labels_all_dev, preds_dev, average=\"macro\")\n",
    "print(f1score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After getting the prediction, F1 score of predicted output is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-15T09:01:44.964494Z",
     "iopub.status.busy": "2022-11-15T09:01:44.963959Z",
     "iopub.status.idle": "2022-11-15T09:01:44.976672Z",
     "shell.execute_reply": "2022-11-15T09:01:44.975200Z",
     "shell.execute_reply.started": "2022-11-15T09:01:44.964459Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Calculate precision\n",
    "matches=0\n",
    "for i,j in zip(labels_all_dev, preds_dev):\n",
    "  if i==j:\n",
    "    matches+=1\n",
    "precision=matches/len(labels_all_dev)\n",
    "print(precision) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(labels_all_dev, preds_dev)\n",
    "\n",
    "# Creating a dataframe for a array-formatted Confusion matrix,so it will be easy for plotting.\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                     index = ['PREAMBLE', 'NONE', 'FAC', 'ARG_RESPONDENT', 'RLC', 'ARG_PETITIONER', 'ANALYSIS', 'PRE_RELIED', 'RATIO', 'RPC', 'ISSUE', 'STA', 'PRE_NOT_RELIED'], \n",
    "                     columns = ['PREAMBLE', 'NONE', 'FAC', 'ARG_RESPONDENT', 'RLC', 'ARG_PETITIONER', 'ANALYSIS', 'PRE_RELIED', 'RATIO', 'RPC', 'ISSUE', 'STA', 'PRE_NOT_RELIED'])\n",
    "\n",
    "#Plotting the confusion matrix\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(cm_df, annot=True)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actal Values')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.savefig(\"matrix_plda.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pecision is calculated"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('NLP_PROJECT')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f4a4a158c887e7abc28dadc0c255c925eb5429f2cdc9bfc614dc11bb760a6fd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
